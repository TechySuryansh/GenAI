{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Customer Churn Prediction Analysis\n",
                "\n",
                "This notebook contains the complete pipeline for predicting customer churn in a telecom environment. \n",
                "\n",
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "import os\n",
                "import json\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, f1_score\n",
                "\n",
                "%matplotlib inline\n",
                "plt.style.use('seaborn-v0_8')\n",
                "DATA_PATH = '../data/WA_Fn-UseC_-Telco-Customer-Churn.csv'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading & Cleaning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(DATA_PATH)\n",
                "print(f\"Initial Shape: {df.shape}\")\n",
                "\n",
                "df = df.drop('customerID', axis=1)\n",
                "df = df.drop('TotalCharges', axis=1)\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocessing & Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "le = LabelEncoder()\n",
                "df['Churn'] = le.fit_transform(df['Churn'])\n",
                "\n",
                "numeric_cols = ['tenure', 'MonthlyCharges']\n",
                "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
                "\n",
                "scaler = StandardScaler()\n",
                "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
                "\n",
                "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
                "feature_names = df.drop('Churn', axis=1).columns.tolist()\n",
                "\n",
                "X = df.drop('Churn', axis=1)\n",
                "y = df['Churn']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "print(f\"Feature Count: {len(feature_names)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Training & Optimization\n",
                "Hyperparameter tuning using Grid Search for both Logistic Regression and Decision Tree models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr_grid = GridSearchCV(LogisticRegression(max_iter=1000), {'C': [0.01, 0.1, 1, 10]}, cv=5, scoring='f1')\n",
                "lr_grid.fit(X_train, y_train)\n",
                "lr_model = lr_grid.best_estimator_\n",
                "\n",
                "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), {'max_depth': [3, 5, 7, 10], 'min_samples_split': [2, 5, 10]}, cv=5, scoring='f1')\n",
                "dt_grid.fit(X_train, y_train)\n",
                "dt_model = dt_grid.best_estimator_\n",
                "\n",
                "print(\"Training Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation & Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models = {'Logistic Regression': lr_model, 'Decision Tree': dt_model}\n",
                "for name, model in models.items():\n",
                "    y_pred = model.predict(X_test)\n",
                "    print(f\"\\n--- {name} ---\")\n",
                "    print(classification_report(y_test, y_pred))\n",
                "    print(f\"ROC-AUC: {roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Saving Artifacts for Dashboard"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs('models', exist_ok=True)\n",
                "joblib.dump(lr_model, 'models/logistic_regression.pkl')\n",
                "joblib.dump(dt_model, 'models/decision_tree.pkl')\n",
                "joblib.dump(scaler, 'models/scaler.pkl')\n",
                "joblib.dump(feature_names, 'models/feature_names.pkl')\n",
                "print(\"Artifacts saved in notebooks/models/\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}